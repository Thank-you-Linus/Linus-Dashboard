"""
Supabase Client for Linus Brain

This module handles all HTTP communication with Supabase.

Key responsibilities:
- Send light action data to Supabase tables
- Fetch automation rules from Supabase
- Handle authentication and error responses
- Use async HTTP client (aiohttp) for non-blocking I/O
"""

import logging
from typing import Any

import aiohttp
from homeassistant.core import HomeAssistant
from homeassistant.helpers.aiohttp_client import async_get_clientsession

_LOGGER = logging.getLogger(__name__)

RULES_TABLE = "area_automation_rules"
INSTANCES_TABLE = "ha_instances"
LIGHT_ACTIONS_TABLE = "light_actions"


class SupabaseClient:
    """
    Async HTTP client for Supabase REST API.

    This client:
    - Uses aiohttp for async HTTP requests
    - Handles authentication with Supabase API keys
    - Sends light action data to Supabase tables
    - Fetches automation rules generated by AI
    """

    def __init__(
        self,
        hass: HomeAssistant,
        supabase_url: str,
        supabase_key: str,
    ) -> None:
        """
        Initialize the Supabase client.

        Args:
            hass: Home Assistant instance
            supabase_url: Supabase project URL (e.g., https://xxx.supabase.co)
            supabase_key: Supabase API key (anon or service key)
        """
        self.hass = hass
        self.supabase_url = supabase_url.rstrip("/")
        self.supabase_key = supabase_key
        self.session = async_get_clientsession(hass)

        # Base URL for REST API
        self.rest_url = f"{self.supabase_url}/rest/v1"

        # Common headers for all requests
        self.headers = {
            "apikey": self.supabase_key,
            "Authorization": f"Bearer {self.supabase_key}",
            "Content-Type": "application/json",
            "Prefer": "return=minimal",
        }

    # ========================================================================
    # HTTP Helper Methods (reduce duplication)
    # ========================================================================

    async def _http_get(
        self,
        url: str,
        params: dict[str, Any] | None = None,
        timeout: int = 10,
        operation: str = "request",
    ) -> tuple[int, Any]:
        """
        Execute HTTP GET request with standard error handling.

        Args:
            url: Full URL to request
            params: Query parameters
            timeout: Request timeout in seconds
            operation: Description of operation for logging

        Returns:
            Tuple of (status_code, response_data)
            - response_data is parsed JSON on success
            - response_data is error text on failure

        Raises:
            aiohttp.ClientError: On HTTP errors
            Exception: On unexpected errors
        """
        try:
            async with self.session.get(
                url,
                params=params,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=timeout),
            ) as response:
                status = response.status
                if status == 200:
                    data = await response.json()
                    return (status, data)
                else:
                    text = await response.text()
                    _LOGGER.error(f"Failed {operation} (status {status}): {text}")
                    return (status, text)

        except aiohttp.ClientError as err:
            _LOGGER.error(f"HTTP error during {operation}: {err}")
            raise
        except Exception as err:
            _LOGGER.error(f"Unexpected error during {operation}: {err}")
            raise

    async def _http_post(
        self,
        url: str,
        payload: dict[str, Any],
        params: dict[str, Any] | None = None,
        timeout: int = 10,
        operation: str = "request",
    ) -> tuple[int, Any]:
        """
        Execute HTTP POST request with standard error handling.

        Args:
            url: Full URL to request
            payload: JSON body to send
            params: Query parameters
            timeout: Request timeout in seconds
            operation: Description of operation for logging

        Returns:
            Tuple of (status_code, response_data)

        Raises:
            aiohttp.ClientError: On HTTP errors
            Exception: On unexpected errors
        """
        try:
            async with self.session.post(
                url,
                json=payload,
                params=params,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=timeout),
            ) as response:
                status = response.status
                if status in (200, 201, 204):
                    # For 204 No Content, return empty dict
                    if status == 204:
                        return (status, {})
                    data = await response.json()
                    return (status, data)
                else:
                    text = await response.text()
                    _LOGGER.error(f"Failed {operation} (status {status}): {text}")
                    return (status, text)

        except aiohttp.ClientError as err:
            _LOGGER.error(f"HTTP error during {operation}: {err}")
            raise
        except Exception as err:
            _LOGGER.error(f"Unexpected error during {operation}: {err}")
            raise

    async def _http_patch(
        self,
        url: str,
        payload: dict[str, Any],
        params: dict[str, Any] | None = None,
        timeout: int = 10,
        operation: str = "request",
    ) -> tuple[int, Any]:
        """
        Execute HTTP PATCH request with standard error handling.

        Args:
            url: Full URL to request
            payload: JSON body to send
            params: Query parameters
            timeout: Request timeout in seconds
            operation: Description of operation for logging

        Returns:
            Tuple of (status_code, response_data)

        Raises:
            aiohttp.ClientError: On HTTP errors
            Exception: On unexpected errors
        """
        try:
            async with self.session.patch(
                url,
                json=payload,
                params=params,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=timeout),
            ) as response:
                status = response.status
                if status in (200, 204):
                    if status == 204:
                        return (status, {})
                    data = await response.json()
                    return (status, data)
                else:
                    text = await response.text()
                    _LOGGER.error(f"Failed {operation} (status {status}): {text}")
                    return (status, text)

        except aiohttp.ClientError as err:
            _LOGGER.error(f"HTTP error during {operation}: {err}")
            raise
        except Exception as err:
            _LOGGER.error(f"Unexpected error during {operation}: {err}")
            raise

    # ========================================================================
    # Public API Methods
    # ========================================================================

    async def fetch_rules(self) -> list[dict[str, Any]]:
        """
        Fetch automation rules from Supabase.

        This method retrieves AI-generated automation rules from the database.
        Rules are expected to have a structure like:
        {
            "id": "rule_123",
            "area": "salon",
            "condition": "presence_detected = true",
            "action": "turn_on_lights",
            "confidence": 0.85,
            "created_at": "2025-10-22T21:00:00Z"
        }

        Returns:
            List of rule dictionaries

        Raises:
            Exception: If HTTP request fails
        """
        url = f"{self.rest_url}/{RULES_TABLE}"

        # Add query parameters to filter active rules only
        params = {
            "active": "eq.true",
            "order": "created_at.desc",
            "limit": "100",
        }

        _LOGGER.debug("Fetching automation rules from Supabase")
        status, data = await self._http_get(url, params=params, operation="fetch rules")

        if status == 200:
            _LOGGER.debug(f"Fetched {len(data)} rules from Supabase")
            return data
        else:
            return []

    async def test_connection(self) -> bool:
        """
        Test the connection to Supabase.

        This is used during configuration to verify credentials.

        Returns:
            True if connection successful, False otherwise
        """
        url = f"{self.rest_url}/"

        try:
            async with self.session.get(
                url,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=5),
            ) as response:
                # Any response (even 404) means we can connect and authenticate
                if response.status in (200, 401, 404):
                    _LOGGER.info("Supabase connection test successful")
                    return True
                else:
                    _LOGGER.error(f"Supabase connection test failed: {response.status}")
                    return False

        except Exception as err:
            _LOGGER.error(f"Supabase connection test failed: {err}")
            return False

    async def get_instance_by_ha_id(
        self, ha_installation_id: str
    ) -> dict[str, Any] | None:
        """
        Get instance information by HA installation ID.

        This method retrieves the instance record for a given HA installation fingerprint.

        Args:
            ha_installation_id: HA core.uuid value

        Returns:
            Instance data dictionary or None if not found

        Raises:
            Exception: If HTTP request fails
        """
        url = f"{self.rest_url}/{INSTANCES_TABLE}"

        params = {
            "ha_installation_id": f"eq.{ha_installation_id}",
            "select": "*",
        }

        _LOGGER.debug(f"Looking up instance for HA installation: {ha_installation_id}")

        status, data = await self._http_get(
            url, params=params, operation="lookup instance"
        )

        if status == 200:
            if data:
                instance = data[0]
                _LOGGER.debug(f"Found instance: {instance['instance_id']}")
                return instance
            else:
                _LOGGER.debug(
                    f"No instance found for HA installation: {ha_installation_id}"
                )
                return None
        else:
            return None

    async def create_new_instance(
        self, ha_installation_id: str, instance_name: str = "Home Assistant"
    ) -> dict[str, Any] | None:
        """
        Create a new instance record for an HA installation.

        This method creates a new instance in the database using the get_or_create_instance function.

        Args:
            ha_installation_id: HA core.uuid value
            instance_name: Human-readable name for the instance

        Returns:
            Created instance data or None if creation failed

        Raises:
            Exception: If HTTP request fails
        """
        # Use RPC to call the get_or_create_instance function
        url = f"{self.rest_url}/rpc/get_or_create_instance"

        payload = {
            "p_ha_installation_id": ha_installation_id,
            "p_instance_name": instance_name,
        }

        try:
            _LOGGER.info(
                f"Creating new instance for HA installation: {ha_installation_id}"
            )

            async with self.session.post(
                url,
                json=payload,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status in (200, 201):
                    instance_id = await response.json()
                    _LOGGER.info(f"Created instance with ID: {instance_id}")

                    # Fetch the full instance data
                    return await self.get_instance_by_ha_id(ha_installation_id)
                else:
                    response_text = await response.text()
                    _LOGGER.error(
                        f"Failed to create instance (status {response.status}): {response_text}"
                    )
                    return None

        except aiohttp.ClientError as err:
            _LOGGER.error(f"HTTP error creating instance: {err}")
            raise
        except Exception as err:
            _LOGGER.error(f"Unexpected error creating instance: {err}")
            raise

    async def update_instance_last_seen(self, instance_id: str) -> bool:
        """
        Update the last_seen timestamp for an instance.

        This method updates the instance's last_seen field to indicate it's still active.

        Args:
            instance_id: The instance UUID

        Returns:
            True if successful, False otherwise

        Raises:
            Exception: If HTTP request fails
        """
        url = f"{self.rest_url}/{INSTANCES_TABLE}"

        params = {
            "instance_id": f"eq.{instance_id}",
        }

        payload = {
            "last_seen": "now()",
            "updated_at": "now()",
        }

        _LOGGER.debug(f"Updating last_seen for instance: {instance_id}")

        status, _ = await self._http_patch(
            url, payload, params=params, operation="update instance last_seen"
        )

        if status in (200, 204):
            _LOGGER.debug(f"Successfully updated last_seen for instance: {instance_id}")
            return True
        else:
            return False

    async def send_light_action(self, data: dict[str, Any]) -> bool:
        """
        Send a light action to Supabase for AI learning.

        This method captures manual light actions with environmental context.

        Example payload:
        {
            "instance_id": "uuid-here",
            "area_id": "salon",
            "area": "Salon",
            "action_type": "turn_on",
            "entity_id": "light.salon_main",
            "old_state": {"state": "off"},
            "new_state": {"state": "on", "brightness": 255},
            "presence_detected": true,
            "illuminance": 45.2,
            "sun_elevation": 15.3,
            "hour": 18,
            "day_of_week": 1,
            "is_manual": true,
            "context_id": "ha_event_context_id"
        }

        Args:
            data: Dictionary containing light action data

        Returns:
            True if successful, False otherwise

        Raises:
            Exception: If HTTP request fails
        """
        url = f"{self.rest_url}/{LIGHT_ACTIONS_TABLE}"

        _LOGGER.debug(
            f"Sending light action for {data.get('entity_id')} in {data.get('area_id', 'unknown')}"
        )

        status, _ = await self._http_post(url, data, operation="send light action")

        if status in (200, 201, 204):
            _LOGGER.debug(f"Successfully sent light action for {data.get('entity_id')}")
            return True
        else:
            return False

    def _transform_cloud_to_local(
        self, cloud_rows: list[dict[str, Any]]
    ) -> dict[str, dict[str, Any]]:
        """
        Transform normalized cloud rules to local nested structure.

        Args:
            cloud_rows: List of normalized rule rows from Supabase

        Returns:
            Dictionary with structure:
            {
                "area_id": {
                    "area_id": "area_id",
                    "area_name": "Area Name",
                    "activity_rules": {
                        "none": {"conditions": [...], "actions": [...]},
                        "presence": {"conditions": [...], "actions": [...]}
                    }
                }
            }
        """
        local_rules: dict[str, dict[str, Any]] = {}

        for row in cloud_rows:
            area_id = row.get("area_id", "unknown")
            area_name = row.get("area_name", area_id.capitalize())
            activity_type = row.get("activity_type", "presence")
            conditions = row.get("conditions", [])
            actions = row.get("actions", [])

            if area_id not in local_rules:
                local_rules[area_id] = {
                    "area_id": area_id,
                    "area_name": area_name,
                    "activity_rules": {},
                }

            local_rules[area_id]["activity_rules"][activity_type] = {
                "conditions": conditions,
                "actions": actions,
            }

        return local_rules

    def _transform_local_to_cloud(
        self, local_rule: dict[str, Any], instance_id: str
    ) -> list[dict[str, Any]]:
        """
        Transform local nested structure to normalized cloud rows.

        Args:
            local_rule: Local rule dictionary with activity_rules structure
            instance_id: The instance UUID

        Returns:
            List of normalized rule dictionaries for Supabase
        """
        cloud_rows = []
        area_id = local_rule.get("area_id", "unknown")
        area_name = local_rule.get("area_name", area_id.capitalize())
        activity_rules = local_rule.get("activity_rules", {})

        for activity_type, rule_data in activity_rules.items():
            cloud_rows.append(
                {
                    "rule_id": f"{area_id}_{activity_type}",
                    "area_id": area_id,
                    "area_name": area_name,
                    "activity_type": activity_type,
                    "instance_id": instance_id,
                    "conditions": rule_data.get("conditions", []),
                    "actions": rule_data.get("actions", []),
                }
            )

        return cloud_rows

    async def fetch_rules_for_instance(
        self, instance_id: str
    ) -> dict[str, dict[str, dict[str, Any]]]:
        """
        Fetch automation rules for a specific instance from Supabase.

        Returns rules grouped by area and activity type.

        Args:
            instance_id: The instance UUID

        Returns:
            Dictionary with structure:
            {
                "salon": {
                    "area_id": "salon",
                    "area_name": "Salon",
                    "activity_rules": {
                        "none": {"conditions": [...], "actions": [...]},
                        "presence": {"conditions": [...], "actions": [...]}
                    }
                }
            }

        Raises:
            Exception: If HTTP request fails
        """
        url = f"{self.rest_url}/active_area_rules"

        params = {
            "instance_id": f"eq.{instance_id}",
            "select": "*",
            "order": "area_id,activity_type",
        }

        try:
            _LOGGER.debug(f"Fetching rules for instance: {instance_id}")

            async with self.session.get(
                url,
                params=params,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status == 200:
                    rules_list = await response.json()
                    _LOGGER.debug(
                        f"Fetched {len(rules_list)} rules for instance {instance_id}"
                    )

                    local_rules = self._transform_cloud_to_local(rules_list)

                    _LOGGER.debug(
                        f"Transformed rules into {len(local_rules)} areas with activity types"
                    )
                    return local_rules

                else:
                    response_text = await response.text()
                    _LOGGER.error(
                        f"Failed to fetch rules (status {response.status}): {response_text}"
                    )
                    return {}

        except aiohttp.ClientError as err:
            _LOGGER.error(f"HTTP error fetching rules: {err}")
            raise
        except Exception as err:
            _LOGGER.error(f"Unexpected error fetching rules: {err}")
            raise

    async def push_rules_for_instance(
        self, instance_id: str, rules: list[dict[str, Any]]
    ) -> bool:
        """
        Push local rules to Supabase using versioned storage.

        This method transforms local nested rules into normalized rows
        and creates new versions using the create_rule_version() function.

        Args:
            instance_id: The instance UUID
            rules: List of local rule dictionaries with activity_rules structure

        Returns:
            True if successful, False otherwise

        Raises:
            Exception: If HTTP request fails
        """
        if not rules:
            _LOGGER.debug("No rules to push")
            return True

        try:
            _LOGGER.debug(f"Pushing {len(rules)} rules for instance: {instance_id}")

            success_count = 0
            for local_rule in rules:
                cloud_rows = self._transform_local_to_cloud(local_rule, instance_id)

                for cloud_row in cloud_rows:
                    url = f"{self.rest_url}/rpc/create_rule_version"

                    payload = {
                        "p_rule_id": cloud_row["rule_id"],
                        "p_area_id": cloud_row["area_id"],
                        "p_area_name": cloud_row["area_name"],
                        "p_activity_type": cloud_row["activity_type"],
                        "p_instance_id": cloud_row["instance_id"],
                        "p_conditions": cloud_row["conditions"],
                        "p_actions": cloud_row["actions"],
                        "p_rule_source": "local_default",
                    }

                    async with self.session.post(
                        url,
                        json=payload,
                        headers=self.headers,
                        timeout=aiohttp.ClientTimeout(total=15),
                    ) as response:
                        if response.status in (200, 201):
                            success_count += 1
                            _LOGGER.debug(f"Created version for {cloud_row['rule_id']}")
                        else:
                            response_text = await response.text()
                            _LOGGER.error(
                                f"Failed to create rule version (status {response.status}): {response_text}"
                            )

            if success_count > 0:
                _LOGGER.info(
                    f"Successfully pushed {success_count} rule versions to Supabase"
                )
                return True
            else:
                _LOGGER.error("Failed to push any rules")
                return False

        except aiohttp.ClientError as err:
            _LOGGER.error(f"HTTP error pushing rules: {err}")
            raise
        except Exception as err:
            _LOGGER.error(f"Unexpected error pushing rules: {err}")
            raise

    async def get_rule_for_area(
        self, instance_id: str, area_id: str
    ) -> dict[str, Any] | None:
        """
        Fetch automation rule for a specific area.

        This method retrieves a single rule for the given area and instance.
        Useful for testing or selectively loading individual rules.

        Args:
            instance_id: The instance UUID
            area_id: The area identifier

        Returns:
            Rule dictionary or None if not found

        Raises:
            Exception: If HTTP request fails
        """
        url = f"{self.rest_url}/{RULES_TABLE}"

        params = {
            "area_id": f"eq.{area_id}",
            "instance_id": f"eq.{instance_id}",
            "active": "eq.true",
            "select": "*",
            "limit": "1",
        }

        try:
            _LOGGER.debug(f"Fetching rule for area {area_id} in instance {instance_id}")

            async with self.session.get(
                url,
                params=params,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status == 200:
                    rules = await response.json()
                    if rules:
                        rule = rules[0]
                        _LOGGER.debug(f"Found rule for area {area_id}")
                        return rule
                    else:
                        _LOGGER.debug(f"No rule found for area {area_id}")
                        return None
                else:
                    response_text = await response.text()
                    _LOGGER.error(
                        f"Failed to fetch rule (status {response.status}): {response_text}"
                    )
                    return None

        except aiohttp.ClientError as err:
            _LOGGER.error(f"HTTP error fetching rule for area: {err}")
            raise
        except Exception as err:
            _LOGGER.error(f"Unexpected error fetching rule for area: {err}")
            raise

    async def fetch_activity_types(
        self, activity_ids: list[str] | None = None
    ) -> dict[str, dict[str, Any]]:
        """
        Fetch activity types from Supabase.

        Args:
            activity_ids: Optional list of specific activity IDs to fetch.
                         If None, fetches all activities.

        Returns:
            Dictionary mapping activity_id to activity data:
            {
                "presence": {
                    "activity_id": "presence",
                    "activity_name": "Presence Detected",
                    "description": "...",
                    "detection_conditions": [...],
                    "duration_threshold_seconds": 0,
                    "timeout_seconds": 60,
                    "is_system": true
                }
            }

        Raises:
            Exception: If HTTP request fails
        """
        url = f"{self.rest_url}/activity_types"

        params = {"select": "*", "order": "activity_id"}

        if activity_ids:
            params["activity_id"] = f"in.({','.join(activity_ids)})"

        try:
            _LOGGER.debug(f"Fetching activity types: {activity_ids or 'all'}")

            async with self.session.get(
                url,
                params=params,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status == 200:
                    activities_list = await response.json()

                    activities_dict = {
                        act["activity_id"]: act for act in activities_list
                    }

                    _LOGGER.debug(f"Fetched {len(activities_dict)} activity types")
                    return activities_dict
                else:
                    response_text = await response.text()
                    _LOGGER.error(
                        f"Failed to fetch activities (status {response.status}): {response_text}"
                    )
                    return {}

        except aiohttp.ClientError as err:
            _LOGGER.error(f"HTTP error fetching activities: {err}")
            raise
        except Exception as err:
            _LOGGER.error(f"Unexpected error fetching activities: {err}")
            raise

    async def fetch_app_with_actions(
        self, app_id: str, version: str | None = None
    ) -> dict[str, Any] | None:
        """
        Fetch an app with all its activity actions.

        Args:
            app_id: The app identifier (e.g., "automatic_lighting")
            version: Optional version timestamp (ISO format).
                    If None, fetches latest version.

        Returns:
            App data with nested activity_actions:
            {
                "app_id": "automatic_lighting",
                "app_name": "Automatic Lighting",
                "description": "...",
                "required_domains": ["light"],
                "recommended_sensors": ["motion", "illuminance"],
                "created_at": "2025-10-26T12:00:00Z",
                "created_by": "system",
                "activity_actions": {
                    "presence": {
                        "activity_id": "presence",
                        "conditions": [...],
                        "actions": [...],
                        "logic": "and",
                        "description": "..."
                    },
                    "none": {...}
                }
            }

        Raises:
            Exception: If HTTP request fails
        """
        try:
            if version:
                app_url = f"{self.rest_url}/automation_apps"
                app_params = {
                    "app_id": f"eq.{app_id}",
                    "created_at": f"eq.{version}",
                    "select": "*",
                    "limit": "1",
                }
            else:
                app_url = f"{self.rest_url}/rpc/get_latest_app_version"
                _LOGGER.debug(f"Getting latest version for app: {app_id}")

                async with self.session.post(
                    app_url,
                    json={"p_app_id": app_id},
                    headers=self.headers,
                    timeout=aiohttp.ClientTimeout(total=10),
                ) as response:
                    if response.status != 200:
                        _LOGGER.error(f"Failed to get latest version for {app_id}")
                        return None

                    version_timestamp = await response.json()

                    if not version_timestamp:
                        _LOGGER.debug(f"No versions found for app: {app_id}")
                        return None

                    app_url = f"{self.rest_url}/automation_apps"
                    app_params = {
                        "app_id": f"eq.{app_id}",
                        "created_at": f"eq.{version_timestamp}",
                        "select": "*",
                        "limit": "1",
                    }

            _LOGGER.debug(f"Fetching app: {app_id} (version: {version or 'latest'})")

            async with self.session.get(
                app_url,
                params=app_params,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status != 200:
                    response_text = await response.text()
                    _LOGGER.error(
                        f"Failed to fetch app (status {response.status}): {response_text}"
                    )
                    return None

                apps = await response.json()

                if not apps:
                    _LOGGER.debug(f"App not found: {app_id}")
                    return None

                app_data = apps[0]

            actions_url = f"{self.rest_url}/app_activity_actions"
            actions_params = {"app_id": f"eq.{app_id}", "select": "*"}

            _LOGGER.debug(f"Fetching actions for app: {app_id}")

            async with self.session.get(
                actions_url,
                params=actions_params,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status != 200:
                    _LOGGER.warning(f"Failed to fetch actions for {app_id}")
                    actions_list = []
                else:
                    actions_list = await response.json()

            activity_actions = {
                action["activity_id"]: {
                    "activity_id": action["activity_id"],
                    "conditions": action.get("conditions", []),
                    "actions": action["actions"],
                    "on_exit": action.get("on_exit"),
                    "logic": action.get("logic", "and"),
                    "description": action.get("description"),
                }
                for action in actions_list
            }

            app_data["activity_actions"] = activity_actions

            _LOGGER.debug(
                f"Fetched app {app_id} with {len(activity_actions)} activity actions"
            )
            return app_data

        except aiohttp.ClientError as err:
            _LOGGER.error(f"HTTP error fetching app: {err}")
            raise
        except Exception as err:
            _LOGGER.error(f"Unexpected error fetching app: {err}")
            raise

    # NOTE: fetch_area_assignments() and assign_app_to_area() methods removed
    # Assignments are now managed by Home Assistant switches, not Supabase tables
    # See: /docs/APP_ASSIGNMENT_ARCHITECTURE.md

    async def fetch_area_insights(self, instance_id: str) -> list[dict[str, Any]]:
        """
        Fetch insights for instance + all global defaults.

        Returns insights where:
        - instance_id matches OR instance_id IS NULL (globals)

        Args:
            instance_id: The instance UUID

        Returns:
            List of insight dictionaries with structure:
            {
                "id": "uuid",
                "instance_id": "uuid" | None,
                "area_id": "salon" | None,
                "insight_type": "dark_threshold_lux",
                "value": {"threshold": 200},
                "confidence": 0.85,
                "metadata": {...},
                "updated_at": "2025-10-27T23:30:00Z"
            }

        Raises:
            Exception: If HTTP request fails
        """
        url = f"{self.rest_url}/area_insights"

        params = {
            "or": f"(instance_id.eq.{instance_id},instance_id.is.null)",
            "select": "*",
            "order": "instance_id.nullslast,area_id.nullslast,insight_type",
        }

        try:
            _LOGGER.debug(f"Fetching area insights for instance: {instance_id}")

            async with self.session.get(
                url,
                params=params,
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=10),
            ) as response:
                if response.status == 200:
                    insights = await response.json()
                    _LOGGER.debug(
                        f"Fetched {len(insights)} insights for instance {instance_id}"
                    )
                    return insights
                else:
                    response_text = await response.text()
                    _LOGGER.error(
                        f"Failed to fetch insights (status {response.status}): {response_text}"
                    )
                    return []

        except aiohttp.ClientError as err:
            _LOGGER.error(f"HTTP error fetching insights: {err}")
            raise
        except Exception as err:
            _LOGGER.error(f"Unexpected error fetching insights: {err}")
            raise
